package parser;

import java.io.IOException;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;

import source.ErrorHandler;
import source.Errors;
import source.Position;
import source.Severity;
import source.Source;
import syms.Scope;
import syms.SymEntry;
import syms.SymbolTable;
import syms.Type;
import tree.BinaryOperator;
import tree.ConstExp;
import tree.DeclNode;
import tree.ExpNode;
import tree.StatementNode;
import tree.Tree;
import tree.UnaryOperator;

/**
 * class Parser - PL0 recursive descent parser. To understand how this parser
 *  works read the notes of recursive descent parsing.
 * @version $Revision: 17 $  $Date: 2013-05-13 08:25:39 +1000 (Mon, 13 May 2013) $ 
 *
 *  The syntax analyzer recognises a PL0 program according to the following
 *  syntax specification using a recursive descent parser. It constructs
 *  the corresponding abstract syntax tree and skeleton symbol table.
 *  PL0 EBNF Grammar:
 *  Program -> Block ENDOFFILE
 *  Block -> { Declaration } CompoundStatement
 *  Declaration -> ConstDefList | TypeDefList | VarDeclList | ProcedureDef
 *  ConstDefList -> KW_CONST ConstDef { ConstDef }
 *  ConstDef -> IDENTIFIER EQUALS Constant SEMICOLON
 *  Constant -> NUMBER | IDENTIFIER | MINUS Constant
 *  TypeDefList -> KW_TYPE TypeDef { TypeDef }
 *  TypeDef -> IDENTIFIER EQUALS Type SEMICOLON
 *  Type -> TypeIdentifier | SubrangeType
 *  TypeIdentifier -> IDENTIFIER
 *  SubrangeType -> LBRACKET Constant RANGE Constant RBRACKET
 *  VarDeclList -> KW_VAR VarDecl { VarDecl }
 *  VarDecl -> IDENTIFIER COLON TypeIdentifier SEMICOLON
 *  ProcedureDef -> ProcedureHead EQUALS Block SEMICOLON
 *  ProcedureHead -> KW_PROCEDURE IDENTIFIER LPAREN RPAREN
 *  CompoundStatement -> KW_BEGIN StatementList KW_END
 *  StatementList -> Statement { SEMICOLON Statement }
 *  Statement -> WhileStatement | IfStatement | CallStatement | Assignment | 
 *               ReadStatement | WriteStatement | CompoundStatement | SkipStatement | ForStatement
 *  Assignment -> LValueList ASSIGN ConditionList
 *  WhileStatement -> KW_WHILE Condition KW_DO Statement
 *  IfStatement -> KW_IF Condition KW_THEN Statement KW_ELSE Statement
 *  CallStatement -> KW_CALL IDENTIFIER LPAREN RPAREN
 *  ReadStatement -> KW_READ LValue
 *  WriteStatement -> KW_WRITE Exp
 *  Skip -> 
 *  ForStatement -> KW_FOR IDENTIFIER COLON LBRACKET Condition RANGE Condition RBRACKET KW_DO Statement
 *  Condition -> Exp [ RelOp Exp ]
 *  ConditionList -> Condition { COMMA Condition }
 *  RelOp   -> EQUALS | NEQUALS | LEQUALS | LESS | GREATER | GEQUALS
 *  Exp     -> [ PLUS | MINUS ] Term   { ( PLUS | MINUS ) Term }
 *  Term    -> Factor { ( TIMES | DIVIDE ) Factor }
 *  Factor  -> LPAREN Condition RPAREN | NUMBER | LValue
 *  LValue -> IDENTIFIER
 *  LValueList -> LValue { COMMA LValue }
 *  
 *
 *  where any constructs not defined by the above productions
 *  are terminal symbols generated by the lexical analyser.
 */
public class Parser {

/******************************* Constants **********************************/

    /* Starting sets for various parsing rules */
    /** Token set with just end of file token */
    private final static TokenSet EOF_SET =
        new TokenSet( Token.EOF );
    /** Set of tokens that may start an LValue. */
    private final static TokenSet LVALUE_START_SET =
        new TokenSet( Token.IDENTIFIER );
    /** Set of tokens that may start a Statement. */
    private final static TokenSet STATEMENT_START_SET =
        LVALUE_START_SET.union( Token.KW_WHILE, Token.KW_IF,
          Token.KW_READ, Token.KW_WRITE,
          Token.KW_CALL, Token.KW_BEGIN, Token.KW_SKIP, Token.KW_FOR );
    /** Set of tokens that may start a Declaration. */
    private final static TokenSet DECLARATION_START_SET =
        new TokenSet( Token.KW_CONST, Token.KW_TYPE, Token.KW_VAR, 
          Token.KW_PROCEDURE );
    /** Set of tokens that may start a Block. */
    private final static TokenSet BLOCK_START_SET =
        DECLARATION_START_SET.union( Token.KW_BEGIN );
    /** Set of tokens that may start a Constant. */
    private final static TokenSet CONSTANT_START_SET = 
        new TokenSet( Token.IDENTIFIER, Token.NUMBER, Token.MINUS );
    /** Set of tokens that may start a Type. */
    private final static TokenSet TYPE_START_SET = 
        new TokenSet( Token.IDENTIFIER, Token.LBRACKET );
    /** Set of tokens that may start a Factor. */
    private final static TokenSet FACTOR_START_SET = 
        LVALUE_START_SET.union( Token.NUMBER, Token.LPAREN );
    /** Set of tokens that may start a Term. */
    private final static TokenSet TERM_START_SET = 
        FACTOR_START_SET;
    /** Set of tokens that may start an Expression. */
    private final static TokenSet EXP_START_SET =
        TERM_START_SET.union( Token.PLUS, Token.MINUS );
    /** Set of tokens that may start a Condition. */
    private final static TokenSet CONDITION_START_SET =
        EXP_START_SET;

    /* Operation sets for relations, expressions, and terms */
    /** Set of tokens representing relational operators. */
    private final static TokenSet REL_OPS_SET =
        new TokenSet( Token.EQUALS, Token.NEQUALS, Token.LESS, Token.GREATER,
          Token.LEQUALS, Token.GEQUALS );
    /** Set of tokens for expression operators. */
    private final static TokenSet EXP_OPS_SET =
        new TokenSet( Token.PLUS, Token.MINUS );
    /** Set of tokens for term operators. */
    private final static TokenSet TERM_OPS_SET =
        new TokenSet( Token.TIMES, Token.DIVIDE );
    
    /*************************** Instance Variables ************************/
    /** The lexical analyzer */
    private Scanner lex;
    /** Control verbose parser debugging output */
    private boolean debugParse;
    /** The current token */
    private LexicalToken token;
    /** Source file handler for the program to be parsed */
    private Source source;
    /** The symbol table */
    private SymbolTable symtab;
    /** The object to report errors to */
    private Errors errors = ErrorHandler.getErrorHandler();
    /** Track nesting depth in parsing rules */
    private int debugLevel = 0;
    
    /****************************** Constructor ****************************/
    /** Construct a parser with the given lexer 
     * @param lex - Scanner object for performing lexical analysis
     * @param debugParse - generate parser debugging output if true 
     * @requires lex != null;
     */
    public Parser( Scanner lex, boolean debugParse ) throws IOException {
        this.lex = lex;
        this.debugParse = debugParse;
        token = lex.getNextToken();      /* Initialise with first token */
        source = lex.getSourceHandler();
        /** Set up a symbol table. 
         * The initial value includes the predefined scope.
         */
        symtab = new SymbolTable();
    }
    /***************************** Public Method ****************************/
    /** Parse the input stream. 
     *  @return constructed tree only if the stream was parsed correctly.
     */
    public Tree.ProgramNode parse() {
        Tree.ProgramNode root =  parseProgram();
        return root;
    }

    /**************************** Support Methods ***************************/
    /** Get the next token and place it in the variable token. 
     * Declare a fatal error on IOException
     * @requires token != Token.EOF;
     */
    private void nextToken() {
        try {
            token = lex.getNextToken();
        } catch( IOException e ) {
            errors.errorMessage( "Caught IOException " + e, Severity.FATAL,
                                Position.NO_POSITION );
            /* Never returns, but just in case: */
            System.exit(1);
        }
    }
    /** Match if token is known to be expected, otherwise there is an error in
     * the compiler. This version used to move on to the next token and give 
     * debugging output if enabled. 
     * @param expected - token expected next in the input stream.
     */
    private void match( Token expected ) {
        pl0_assert( token.isMatch( expected ), 
                "Match assertion failed on " + expected );
        debugMessage( "Matched " + tokenString( token ) );
        nextToken();
    }
    /** Match a token equal to that expected.
     * If the current token is the expected token, it is skipped,
     * otherwise an error is reported and error recovery attempted.
     * For the error recovery, if the current token can follow the expected
     * token, then it is assumed that the expected token was omitted and
     * no error recovery is necessary, otherwise the current token is skipped.
     * If the current token is skipped then the next token may be the
     * expected token, if so, it is matched.
     * @param expected - token expected next in the input stream.
     * @param follows - set of tokens expected to follow the expected token.
     * @requires follows is nonempty
     */
    private void match( Token expected, TokenSet follows ) {
        if( token.isMatch( expected ) ) {
            match( expected );
        } else {
            debugMessage( "Parse error, expecting '" + expected + "'" );
            error( "Parse error, expecting '" + expected + "'" );
            /* If the current token may follow the expected token then
             * treat it as though the expected token was missing and
             * do no further error recovery.
             */ 
            if( ! token.isIn( follows ) && !token.isMatch( Token.EOF ) ) {
                // Skip the erroneous token
                debugMessage( "Skipping " + tokenString( token ) );
                nextToken();
                /* If after skipping, the (new) token is not the expected 
                 * token we do no further error recovery (in match at least).
                 */
                if( token.isMatch( expected ) ) {
                    /* If after skipping the erroneous token we find 
                     * the expected token we match it
                     */
                    match( expected );
                }
            }
        }
    }
    /** Match when follow set is a single token
     * @param expected - token expected next in the input stream.
     * @param follows - single token that may follow
     */
    private void match( Token expected, Token follows ) {
        match( expected, new TokenSet( follows ) );
    }
    /** Return token name and position as debug string */
    private String tokenString( LexicalToken token ) {
        return "'" + token.toString() + "'" + 
            " at line " + source.getLineNumber( token.getPosn() ) +
            " column " + source.offset( token.getPosn() );
    }
    /** Skip tokens until one is found which is in the parameter set find. 
     * Used for error recovery. 
     * @param find - set of tokens: skip until one found in this set
     * @requires find.contains( Token.EOF ); 
     */
    private void skipTo( TokenSet find ) {
        while( ! token.isIn( find ) ) {
            debugMessage( "Skipping " + tokenString( token ) );
            nextToken();
        }
    }
    /** Begin a parsing rule. 
     * Ensure that the next token is in the set of tokens expected 
     * at the start of a grammar rule. 
     * An error is reported if it isn't.
     * @param rule - name of the rule for use in error messages
     * @param expected - set of tokens expected at start of rule
     * @param recoverSet - set of tokens to recover at on a syntax error
     * @return true iff an expected token was (eventually) found.
     */
    private boolean beginRule( String rule, TokenSet expected,
            TokenSet recoverSet ) {
        debugMessage( "Begin parse " + rule + " recover on " + recoverSet );
        debugLevel++;
        if( ! token.isIn( expected ) ) {
            error( token + " cannot start " + rule );
            debugMessage( token + " cannot start " + rule );
            skipTo( recoverSet.union( expected ) );
            if( !token.isIn( expected ) ) {
                debugLevel--; /* Decrease as this beginRule failed */
                return false;
            }
        }
        return true;
    }
    /** Begin a parsing rule. 
     * Same as above, except that expected is a single token.
     * @param rule - name of the rule for use in error messages
     * @param expected - token expected at start of rule
     * @param recoverSet set of tokens to recover at on a syntax error
     * @return true iff an expected token was (eventually) found.
     */
    private boolean beginRule( String rule, Token expected,
            TokenSet recoverSet) {
        return beginRule( rule, new TokenSet( expected ), recoverSet );
    }
    /** Version of beginRule when failure indicates that there
     * is an error in the PL0 compiler.
     * @param rule - name of the rule for use in error messages
     * @param expected - set of tokens expected at start of rule
     */
    private void beginRule( String rule, TokenSet expected ) {
        debugMessage( "Begin parse " + rule );
        debugLevel++;
        if( ! token.isIn( expected ) ) {
            fatal( token + " cannot start " + rule );
            // doesn't return from fatal error
        }
    }
    /** Version of beginRule when failure indicates that there
     * is an error in the PL0 compiler.
     * Same as above, except that expected is a single token.
     * @param rule - name of the rule for use in error messages
     * @param - expected token expected at start of rule
     */
    private void beginRule( String rule, Token expected ) {
        beginRule( rule, new TokenSet( expected ) );
    }
    /** End a parsing rule.
     * Ensure that the current token is a member of the recovery set 
     * (i.e., something which an ancestor rule is expecting).
     * @param rule name of the rule for use in error messages
     * @param recoverSet set of tokens to recover at on a syntax error
     * @requires recoverSet.contains( Token.EOF);
     */
    private void endRule( String rule, TokenSet recoverSet ) {
        if( ! token.isIn( recoverSet ) ) {
            error( token + " cannot follow " + rule );
            debugMessage( token + " cannot follow " + rule );
            // Skipping cannot fail as recoverSet must contain end of file (EOF)
            skipTo( recoverSet );
        }
        debugLevel--;  /* Decrease debugging level at end of rule */
        debugMessage( "End parse " + rule );
    }
    /** Output debugging message if debug turned on */
    private void debugMessage( String msg ) {
        if( debugParse ) {
            /* Indent message by the level of nesting of parsing rules */
            String indent = "";
            for( int i = 1; i <= debugLevel; i++ ) {
                indent += " ";
            }
            System.out.println( indent + msg );
        }
    }
   
    /**************************** Parsing Methods ***************************/

    /** RULE: Program -> Block ENDOFFILE */
    private Tree.ProgramNode parseProgram( ) {
        if( !beginRule( "Program", BLOCK_START_SET, EOF_SET ) ) {
            return null;
        }
        SymEntry.ProcedureEntry proc = 
            symtab.addProcedure( "<Main>", token.getPosn() );
        if( proc  == null ) {
            fatal( "Could not add main program to symbol table" );
        }
        Scope blockLocals = symtab.newScope();
        proc.setLocalScope( blockLocals );
        Tree.BlockNode block = parseBlock( EOF_SET );
        block.setBlockLocals( blockLocals );
        symtab.leaveScope();
        /* We can't use match because there is nothing following end of file */
        endRule( "Program", EOF_SET );
        return new Tree.ProgramNode( symtab, block );
    }
    /** RULE: Block -> { Declaration } CompoundStatement */
    private Tree.BlockNode parseBlock( TokenSet recoverSet ) {
        DeclNode.DeclListNode procedures = new DeclNode.DeclListNode();
        if( !beginRule("Block", BLOCK_START_SET, recoverSet)) {
            return new Tree.BlockNode( procedures, 
                    new StatementNode.ErrorNode( token.getPosn()) );
        }
        while( token.isIn( DECLARATION_START_SET ) ) {
            procedures = parseDeclaration( procedures, 
                        recoverSet.union( BLOCK_START_SET ) );
        }
        StatementNode statements = parseCompoundStatement( recoverSet );
        endRule( "Block", recoverSet );
        return new Tree.BlockNode( procedures, statements );
    }
    /** RULE:
     *  Declaration -> ConstDefList | TypeDefList | VarDeclList | ProcedureDef 
     */
    private DeclNode.DeclListNode parseDeclaration( 
            DeclNode.DeclListNode procedures, TokenSet recoverSet ) {
        beginRule( "Declaration", DECLARATION_START_SET ); /* cannot fail */
        if( token.isMatch( Token.KW_CONST ) ) {
            parseConstDefList( recoverSet );
        } else if( token.isMatch( Token.KW_TYPE ) ) {
            parseTypeDefList( recoverSet );
        } else if( token.isMatch( Token.KW_VAR ) ) {
            parseVarDeclList( recoverSet );
        } else if( token.isMatch( Token.KW_PROCEDURE ) ) {
            DeclNode.ProcedureNode proc = parseProcedureDef( recoverSet );
            procedures.addDeclaration( proc );
        } else { // cannot get here
            fatal( "parseDeclaration", token.getPosn() );
        }
        endRule( "Declaration", recoverSet );
        return procedures;
    }
    /** Rule: ConstDefList -> KW_CONST ConstDef { ConstDef } */
    private void parseConstDefList( TokenSet recoverSet ) {
        beginRule( "Constant Definition List", Token.KW_CONST ); /* cannot fail */
        match( Token.KW_CONST );
        do {
            parseConstDef( recoverSet.union( Token.IDENTIFIER ) );
        } while( token.isMatch( Token.IDENTIFIER ) );
        endRule( "Constant Definition List", recoverSet );
    }
    /** Rule: ConstDef -> IDENTIFIER EQUALS Constant SEMICOLON */
    private void parseConstDef( TokenSet recoverSet ) {
        if( !beginRule("Constant Definition", Token.IDENTIFIER, recoverSet) ) {
            return;
        }
        LexicalToken constToken = token; /* save IDENTIFIER token */
        match( Token.IDENTIFIER );       /* cannot fail */
        match( Token.EQUALS, CONSTANT_START_SET );
        ConstExp tree = 
            parseConstant( recoverSet.union( Token.SEMICOLON ) );
        if( symtab.addConstant( constToken.getName(), constToken.getPosn(), 
                                    tree ) == null ) {
                error( "Constant identifier " + constToken.getName() + 
                    " already declared in this scope", constToken.getPosn() );
        }
        match( Token.SEMICOLON, recoverSet );
        endRule( "Constant Definition", recoverSet );
    }
    /** Rule: Constant -> NUMBER | IDENTIFIER | MINUS Constant */
    private ConstExp parseConstant( TokenSet recoverSet ) {
        if( !beginRule( "Constant", CONSTANT_START_SET, recoverSet ) ) {
            /* Defaults to error node on error */
            return new ConstExp.ErrorNode( token.getPosn(), 
                    symtab.getCurrentScope() );
        }
        ConstExp tree;  
        if( token.isMatch( Token.NUMBER ) ) {
            tree = new ConstExp.NumberNode( token.getPosn(), 
                     symtab.getCurrentScope(), Type.INTEGER_TYPE, 
                     token.getIntValue() );
            match( Token.NUMBER ); /* cannot fail */
        } else if( token.isMatch( Token.IDENTIFIER ) ) {
            tree = new ConstExp.ConstIdNode( token.getPosn(),
                    symtab.getCurrentScope(), token.getName());
            match( Token.IDENTIFIER ); /* cannot fail */
        } else if( token.isMatch( Token.MINUS ) ) {
            Position pos = token.getPosn();
            match( Token.MINUS ); /* cannot fail */
            tree = parseConstant( recoverSet );
            tree = new ConstExp.NegateNode( pos, 
                    symtab.getCurrentScope(), tree );
        } else {
            tree = null;
            fatal( "parseConstant" ); /* cannot get here */
        }
        endRule( "Constant", recoverSet );
        return tree;
    }
    /** Rule: TypeDefList -> KW_TYPE TypeDef { TypeDef }  */
    private void parseTypeDefList( TokenSet recoverSet ) {
        beginRule( "Type Definition List", Token.KW_TYPE ); /* cannot fail */
        match( Token.KW_TYPE );
        do {
            parseTypeDef( recoverSet.union( Token.IDENTIFIER ) );
        } while( token.isMatch( Token.IDENTIFIER ) );
        endRule( "Type Definition List", recoverSet );
    }
    /** Rule: TypeDef -> IDENTIFIER EQUALS Type SEMICOLON */
    private void parseTypeDef( TokenSet recoverSet ) {
        if( !beginRule("Type Definition", Token.IDENTIFIER, recoverSet ) ) {
            return;
        }
        LexicalToken typeIdToken = token; /* save IDENTIFIER token */
        match( Token.IDENTIFIER );        /* cannot fail */
        match( Token.EQUALS, TYPE_START_SET );
        Type type = parseType( recoverSet.union( Token.SEMICOLON ) );
        if( symtab.addType(typeIdToken.getName(), 
                           typeIdToken.getPosn(), type) == null ){
            error( "Type identifier " + typeIdToken.getName() + 
                   " already declared in this scope", typeIdToken.getPosn() );
        }
        match( Token.SEMICOLON, recoverSet );
        endRule( "Type Definition", recoverSet );
    }
    /** Rule: Type -> TypeIdentifier | SubrangeType */
    private Type parseType( TokenSet recoverSet ) {        
        if( ! beginRule( "Type", TYPE_START_SET, recoverSet ) ) {
            return Type.ERROR_TYPE;
        }
        Type type = null;
        if( token.isMatch( Token.IDENTIFIER ) ) {
            type = parseTypeIdentifier( recoverSet );
        } else if( token.isMatch( Token.LBRACKET ) ) {
            type = parseSubrangeType( recoverSet );
        } else {
            fatal( "parseType", token.getPosn() );
        }
        endRule( "Type", recoverSet );
        return type;
    }
    /** Rule: SubrangeType -> LBRACKET Constant RANGE Constant RBRACKET */
    private Type parseSubrangeType( TokenSet recoverSet ) {        
        if( ! beginRule( "Subrange Type", Token.LBRACKET, recoverSet ) ) {
            return Type.ERROR_TYPE;
        }
        match( Token.LBRACKET ); /* cannot fail */
        ConstExp lower, upper;
        lower = parseConstant( recoverSet.union( Token.RANGE ) );
        match( Token.RANGE, CONSTANT_START_SET );
        upper = parseConstant( recoverSet.union( Token.RBRACKET ) );
        match( Token.RBRACKET, recoverSet );
        endRule( "Type", recoverSet );
        return new Type.SubrangeType( lower, upper );
    }
    /** Rule: TypeIdentifier -> IDENTIFIER */
    private Type parseTypeIdentifier( TokenSet recoverSet ) {
        if( ! beginRule( "Type Identifier", Token.IDENTIFIER, recoverSet ) ) {
            return Type.ERROR_TYPE;
        }
        LexicalToken idToken = token; /* save IDENTIFIER token */
        match( Token.IDENTIFIER );    /* cannot fail */
        endRule( "Type Identifier", recoverSet );
        return new Type.IdRefType( idToken.getName(), 
                symtab.getCurrentScope(), idToken.getPosn() );
    }
    /** Rule: VarDeclList -> KW_VAR VarDecl { VarDecl }  */
    private void parseVarDeclList( TokenSet recoverSet ) {
        beginRule( "Variable Declaration List", Token.KW_VAR ); // cannot fail
        match( Token.KW_VAR ); /* cannot fail */
        do {
            parseVarDecl( recoverSet.union( Token.IDENTIFIER ) );
        } while( token.isMatch( Token.IDENTIFIER ) ); 
        endRule( "Variable Declaration List", recoverSet );
    }
    /** Rule: VarDecl -> IDENTIFIER COLON TypeIdentifier SEMICOLON */
    private void parseVarDecl( TokenSet recoverSet ) {
        if(!beginRule("Variable Declaration", Token.IDENTIFIER, recoverSet)) {
            return;
        }
        LexicalToken varToken = token; /* save IDENTIFIER token */
        match( Token.IDENTIFIER );     /* cannot fail */
        match( Token.COLON, TYPE_START_SET );
        Type type = parseTypeIdentifier( recoverSet.union( Token.SEMICOLON ) );
        // The type of a variable must be a reference type
        if( symtab.addVariable( varToken.getName(), varToken.getPosn(), 
                new Type.ReferenceType(type) ) == null ) {
            error( "Variable identifier " + varToken.getName() + 
                   " already declared in this scope", varToken.getPosn() );
        }
        match( Token.SEMICOLON, recoverSet );
        endRule( "Variable Declaration", recoverSet );
    }
    /** Rule: ProcedureDef -> ProcedureHead EQUALS Block SEMICOLON */
    private DeclNode.ProcedureNode parseProcedureDef( TokenSet recoverSet ) {
        beginRule( "Procedure Definition", Token.KW_PROCEDURE ); // can't fail
        /* A common syntax error is to forget the EQUALS, hence the 
         * recovery set contains tokens that can follow the EQUALS as well.
         * In general the recovery set can include tokens appearing later in
         * the production than immediately following tokens.
         */
        SymEntry.ProcedureEntry procEntry = parseProcedureHead( 
                recoverSet.union( Token.EQUALS ).union( BLOCK_START_SET ) );
        Scope blockLocals = symtab.newScope();
        procEntry.setLocalScope( blockLocals );
        match( Token.EQUALS, BLOCK_START_SET );
        Tree.BlockNode block = parseBlock(recoverSet.union(Token.SEMICOLON));
        block.setBlockLocals( blockLocals );
        symtab.leaveScope();
        match( Token.SEMICOLON, recoverSet );
        endRule( "Procedure Definition", recoverSet );
        return new DeclNode.ProcedureNode( procEntry, block );
    }
    /** Rule: ProcedureHead -> KW_PROCEDURE IDENTIFIER LPAREN RPAREN */
    private SymEntry.ProcedureEntry parseProcedureHead(TokenSet recoverSet) {
        beginRule( "Procedure Header", Token.KW_PROCEDURE ); /* cannot fail */
        SymEntry.ProcedureEntry procEntry;
        match( Token.KW_PROCEDURE );
        if( token.isMatch( Token.IDENTIFIER ) ) {
            procEntry = symtab.addProcedure(token.getName(),token.getPosn());
            if( procEntry  == null ) {
                procEntry = new SymEntry.ProcedureEntry( token.getName(), 
                        token.getPosn(), symtab.getCurrentScope() );
                error( "Procedure identifier " + token.getName() +
                       " already declared in this scope" );
            }
        } else {
            /* Provide dummy procedure entry (not in the symbol table) */
            procEntry = new SymEntry.ProcedureEntry( "<undefined>", 
                    token.getPosn(), symtab.getCurrentScope() );
        }
        match( Token.IDENTIFIER, Token.LPAREN );
        match( Token.LPAREN, Token.RPAREN );
        // parameters would go here
        match( Token.RPAREN, recoverSet );
        endRule( "Procedure Header", recoverSet );
        return procEntry;
    }
    /** Rule: CompoundStatement -> BEGIN StatementList END  */
    private StatementNode parseCompoundStatement( TokenSet recoverSet ) {
        /* In case KW_BEGIN is missing, the recovery set is non-standard
         * and contains tokens that can start a statement.
         */
        if( !beginRule( "Compound Statement", Token.KW_BEGIN, 
                   recoverSet.union( STATEMENT_START_SET ) ) ) {
            return new StatementNode.ListNode( token.getPosn() );
        }
        match( Token.KW_BEGIN, STATEMENT_START_SET );
        StatementNode result = 
            parseStatementList( recoverSet.union( Token.KW_END ));
        match( Token.KW_END, recoverSet );
        endRule( "Compound Statement", recoverSet );
        return result;
    }
    /** Rule: StatementList -> Statement { SEMICOLON Statement }  */
    private StatementNode parseStatementList( TokenSet recoverSet ) {
        // Initialize result to an empty list of statements
        StatementNode.ListNode result = 
                new StatementNode.ListNode( token.getPosn() );
        if( !beginRule("Statement List",STATEMENT_START_SET,recoverSet) ) {
            return result;
        }
        StatementNode s = 
            parseStatement( recoverSet.union( Token.SEMICOLON ) );
        result.addStatement( s );
        
        while( token.isMatch( Token.SEMICOLON ) ) {
            match( Token.SEMICOLON );
            s = parseStatement( recoverSet.union( Token.SEMICOLON ) );
            result.addStatement( s );
        }
        endRule( "Statement List", recoverSet );
        return result;
    }
    /** Rule: Statement -> Assignment | WhileStatement | IfStatement
     *                  | ReadStatement | WriteStatement | CallStatement
     *                  | CompoundStatement | SkipStatement
     */
    private StatementNode parseStatement( TokenSet recoverSet ) {
        StatementNode result;
        if ( !beginRule( "Statement", STATEMENT_START_SET, recoverSet ) ) {
            return new StatementNode.ErrorNode( token.getPosn() );
        }
        switch( token.getKind() ) {
        case IDENTIFIER:
            result = parseAssignment( recoverSet ); 
            break;
        case KW_WHILE:
            result = parseWhileStatement( recoverSet ); 
            break;
        case KW_IF:
            result = parseIfStatement( recoverSet ); 
            break;
        case KW_READ:
            result = parseReadStatement( recoverSet ); 
            break;
        case KW_WRITE:
            result = parseWriteStatement( recoverSet ); 
            break;
        case KW_CALL:
            result = parseCallStatement( recoverSet ); 
            break;
        case KW_BEGIN:
            result = parseCompoundStatement( recoverSet ); 
            break;
        case KW_SKIP:
        	result = parseSkipStatement( recoverSet );
        	break;
        case KW_FOR:
        	result = parseForStatement( recoverSet );
        	break;
        default:
            fatal( "parse Statement " );
            result = new StatementNode.ErrorNode( token.getPosn() );
        }
        endRule( "Statement", recoverSet );
        return result;
    }
    
    /** Rule : Skip -> */
    private StatementNode parseSkipStatement( TokenSet recoverSet ){
    	beginRule("Skip Statement", Token.KW_SKIP); //cannot fail
    	Position pos = token.getPosn();
    	match(Token.KW_SKIP); //cannot fail
    	endRule("Skip Statement", recoverSet);
    	return new StatementNode.SkipNode(pos);
    	 
    }
    
    
//    /** Rule: Assignment -> LValueList ASSIGN ConditionList */
//    private StatementNode.AssignmentNode parseAssignment(TokenSet recoverSet) {
//        beginRule( "Assignment", LVALUE_START_SET, recoverSet );
//        /* Non-standard recovery set includes EQUALS because a common syntax
//         * error is to use EQUALS instead of ASSIGN.
//         */
//        ExpNode left = parseLValue( 
//                recoverSet.union( Token.ASSIGN, Token.EQUALS ) );
//        Position pos = token.getPosn();
//        match( Token.ASSIGN, CONDITION_START_SET );
//        ExpNode right = parseCondition( recoverSet );
//        endRule( "Assignment", recoverSet );
//        return new StatementNode.AssignmentNode( pos, left, right );
//    }
    
    /** Rule: Assignment -> LValueList ASSIGN ConditionList */
    private StatementNode.AssignmentNode parseAssignment(TokenSet recoverSet) {
        beginRule( "Assignment", LVALUE_START_SET, recoverSet );
        /* Non-standard recovery set includes EQUALS because a common syntax
         * error is to use EQUALS instead of ASSIGN.
         */
        List<ExpNode> left = parseLValueList( 
                recoverSet.union( Token.ASSIGN, Token.EQUALS ) );
        Position pos = token.getPosn();
        match( Token.ASSIGN, CONDITION_START_SET );
        List<ExpNode> right = parseConditionList( recoverSet );
        endRule( "Assignment", recoverSet );
        return new StatementNode.AssignmentNode( pos, left, right );
    }
    
    /** Rule: LValueList -> LValue { COMMA LValue } */
    private List<ExpNode> parseLValueList(TokenSet recoverSet) {
    	
    	List<ExpNode> result = new ArrayList<ExpNode>();
    	if( !beginRule( "LValueList", Token.IDENTIFIER, recoverSet ) ) {
            return result;
        }
    	
        ExpNode var = parseLValue(recoverSet.union(Token.COMMA));
        result.add(var);
        
        while(token.isMatch(Token.COMMA)){
        	match(Token.COMMA);
        	var = parseLValue(recoverSet.union(Token.COMMA));
            result.add(var);
        }
        endRule( "LValueList", recoverSet );
        return result;
    }
    
    /**Rule: ConditionList -> Condition { COMMA Condition } */
    private List<ExpNode> parseConditionList(TokenSet recoverSet){
    	
    	List<ExpNode> result = new ArrayList<ExpNode>();
    	
    	if( !beginRule( "ConditionList", CONDITION_START_SET, recoverSet ) ) {
            return result;
        }
        ExpNode cond = parseCondition(recoverSet.union(Token.COMMA));
        result.add(cond);
        
        while(token.isMatch(Token.COMMA)){
        	match(Token.COMMA);
        	cond = parseCondition(recoverSet.union(Token.COMMA));
        	result.add(cond);
        }
        endRule( "ConditionList", recoverSet );
        return result;
    	
    	
    	
    }
    
    /** Rule: WhileStatement -> KW_WHILE Condition KW_DO Statement */
    private StatementNode parseWhileStatement( TokenSet recoverSet ) {
        beginRule( "While Statement", Token.KW_WHILE ); // cannot fail
        Position pos = token.getPosn();
        match( Token.KW_WHILE ); /* cannot fail */
        ExpNode cond = parseCondition( recoverSet.union( Token.KW_DO ) );
        match( Token.KW_DO, STATEMENT_START_SET );
        StatementNode statement = parseStatement( recoverSet );
        endRule( "While Statement", recoverSet );
        return new StatementNode.WhileNode( pos, cond, statement );
    }
    /** Rule: IfStatement -> KW_IF Condition KW_THEN Statement KW_ELSE Statement
     */
    private StatementNode parseIfStatement( TokenSet recoverSet ) {
        beginRule( "If Statement", Token.KW_IF ); /* cannot fail */
        match( Token.KW_IF ); /* cannot fail */
        Position pos = token.getPosn();
        ExpNode cond = parseCondition( recoverSet.union( Token.KW_THEN ) );
        match( Token.KW_THEN, STATEMENT_START_SET );
        StatementNode thenClause = 
            parseStatement( recoverSet.union( Token.KW_ELSE ) );
        match( Token.KW_ELSE, STATEMENT_START_SET );
        StatementNode elseClause = parseStatement( recoverSet );
        endRule( "If Statement", recoverSet );
        return new StatementNode.IfNode( pos, cond, thenClause, elseClause );
    }
    
    /** Rule: ForStatement -> KW_FOR IDENTIFIER COLON LBRACKET Condition RANGE Condition 
     * 							RBRACKET KW_DO Statement
     */
    private StatementNode parseForStatement( TokenSet recoverSet ) {
        beginRule( "For Statement", Token.KW_FOR ); /* cannot fail */
        match( Token.KW_FOR ); /* cannot fail */
        Position pos = token.getPosn();
        String id;
        if(token.isMatch(Token.IDENTIFIER)){
        	
        	id = token.getName();
        	
        } else {
        	
        	id = "<no id>";
        	
        }
        match(Token.IDENTIFIER, Token.COLON);
        match(Token.COLON, Token.RBRACKET);
        match(Token.LBRACKET, CONDITION_START_SET);
        ExpNode lowerBound = parseCondition( recoverSet.union( Token.RANGE ) ); // should the recoverset just consist of range?
        match( Token.RANGE, CONDITION_START_SET );
        ExpNode upperBound = parseCondition( recoverSet.union( Token.RBRACKET ) );
        match(Token.RBRACKET, recoverSet.union(Token.KW_DO));
        match(Token.KW_DO, STATEMENT_START_SET);
        StatementNode doStmt = 
            parseStatement( recoverSet );
       
        endRule( "For Statement", recoverSet );
        return new StatementNode.ForNode( pos, id, lowerBound, upperBound, doStmt  );
    }
    
    
    /** Rule: ReadStatement -> KW_READ LValue */
    private StatementNode parseReadStatement( TokenSet recoverSet ) {
        beginRule( "Read Statement", Token.KW_READ ); /* cannot fail */
        match( Token.KW_READ ); /* cannot fail */
        Position pos = token.getPosn();
        ExpNode lval = parseLValue( recoverSet );
        List<ExpNode> left = new ArrayList<ExpNode>();
        left.add(lval);
        List<ExpNode> right = new ArrayList<ExpNode>();
        endRule( "Read Statement", recoverSet );
        right.add(new ExpNode.ReadNode( pos ));
        // A read statement is treated as an assignment of the value read
        // to the variable. A ReadNode is an expression.
        return new StatementNode.AssignmentNode( pos, left, 
                        right );
    }
    /** Rule: WriteStatement -> KW_WRITE Exp */
    private StatementNode parseWriteStatement( TokenSet recoverSet ) {
        beginRule( "Write Statement", Token.KW_WRITE ); // cannot fail
        match( Token.KW_WRITE ); /* cannot fail */
        Position pos = token.getPosn();
        ExpNode exp = parseExp( recoverSet );
        endRule( "Write Statement", recoverSet );
        return new StatementNode.WriteNode( pos, exp );
    }
    /** Rule: CallStatement -> KW_CALL IDENTIFIER LPAREN RPAREN */
    private StatementNode parseCallStatement( TokenSet recoverSet ) {
        beginRule( "Call Statement", Token.KW_CALL ); // cannot fail
        match( Token.KW_CALL ); /* cannot fail */
        Position pos = token.getPosn();
        String procId;
        if( token.isMatch( Token.IDENTIFIER ) ) {
            procId = token.getName();
        } else {
            procId = "<noid>";
        }
        match( Token.IDENTIFIER, Token.LPAREN );
        match( Token.LPAREN, Token.RPAREN );
        // actual parameters would go here
        match( Token.RPAREN, recoverSet );
        endRule( "Call Statement", recoverSet );
        return new StatementNode.CallNode( pos, procId 
                );
    }
    /** Rule: Condition -> Exp [ RelOp Exp ] */
    private ExpNode parseCondition( TokenSet recoverSet ) {
        if( !beginRule( "Condition", CONDITION_START_SET, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode cond = parseExp( recoverSet.union( REL_OPS_SET ) );
        if( token.isIn( REL_OPS_SET ) ) {
            Position pos = token.getPosn();
            BinaryOperator operatorCode = 
                parseRelOp( recoverSet.union( EXP_START_SET ) );
            ExpNode right = parseExp( recoverSet );
            cond = new ExpNode.BinaryOpNode( pos, operatorCode, 
                                           cond, right );
        }
        endRule( "Condition", recoverSet );
        return cond;
    }
    /** Rule: RelOp -> EQUALS | NEQUALS | LEQUALS | LESS | GREATER | GEQUALS */
    private BinaryOperator parseRelOp( TokenSet recoverSet ) {
        beginRule( "RelOp", REL_OPS_SET ); // cannot fail
        BinaryOperator operatorCode = BinaryOperator.INVALID_OP;
        switch( token.getKind() ) {
        case EQUALS:
            operatorCode = BinaryOperator.EQUALS_OP;
            match( Token.EQUALS ); /* cannot fail */
            break;
        case NEQUALS:
            operatorCode = BinaryOperator.NEQUALS_OP;
            match( Token.NEQUALS ); /* cannot fail */
            break;
        case LESS:
            operatorCode = BinaryOperator.LESS_OP;
            match( Token.LESS ); /* cannot fail */
            break;
        case GREATER:
            operatorCode = BinaryOperator.GREATER_OP; 
            match( Token.GREATER ); /* cannot fail */
            break;
        case LEQUALS:
            operatorCode = BinaryOperator.LEQUALS_OP;
            match( Token.LEQUALS ); /* cannot fail */
            break;
        case GEQUALS:
            operatorCode = BinaryOperator.GEQUALS_OP;
            match( Token.GEQUALS ); /* cannot fail */
            break;
        default:
            fatal( "Unreachable branch in parseCondition" );
        }
        endRule( "RelOp", recoverSet );
        return operatorCode;
    }
    /** Rule: Exp -> [ PLUS | MINUS ] Term { ( PLUS | MINUS ) Term } */
    private ExpNode parseExp( TokenSet recoverSet ) {
        if( !beginRule( "Expression", EXP_START_SET, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        boolean haveUnaryMinus = false;
        Position pos = token.getPosn();
        if( token.isMatch( Token.MINUS ) ) {
            haveUnaryMinus = true;
            match( Token.MINUS ); /* cannot fail */
        } else if( token.isMatch( Token.PLUS ) ) {
            match( Token.PLUS ); /* cannot fail */
        }
        ExpNode exp = parseTerm( recoverSet.union( EXP_OPS_SET ) );
        if( haveUnaryMinus ) {
            exp = new ExpNode.UnaryOpNode( pos, UnaryOperator.NEG_OP, exp );
        }
        while( token.isIn( EXP_OPS_SET ) ) {
            BinaryOperator operatorCode = BinaryOperator.INVALID_OP;
            pos = token.getPosn();
            if ( token.isMatch( Token.MINUS ) ) {
                operatorCode = BinaryOperator.SUB_OP;
                match( Token.MINUS ); /* cannot fail */
            } else if ( token.isMatch( Token.PLUS ) ) {
                operatorCode = BinaryOperator.ADD_OP;
                match( Token.PLUS ); /* cannot fail */
            } else {
                fatal( "Unreachable branch in parseExp" );
            }
            ExpNode right = parseTerm( recoverSet.union( EXP_OPS_SET ) );
            exp = new ExpNode.BinaryOpNode( pos, operatorCode, exp, right );
        }
        endRule( "Expression", recoverSet );
        return exp;
    }
    /** Rule: Term  -> Factor { ( TIMES | DIVIDE ) Factor }  */
    private ExpNode parseTerm( TokenSet recoverSet ) {
        if( !beginRule( "Term", TERM_START_SET, recoverSet ) ) {
            return new  ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode term = parseFactor( recoverSet.union( TERM_OPS_SET ) );
        while( token.isIn( TERM_OPS_SET ) ) {
            BinaryOperator operatorCode = BinaryOperator.INVALID_OP;
            Position pos = token.getPosn();
            if ( token.isMatch( Token.TIMES ) ) {
                operatorCode = BinaryOperator.MUL_OP;
                match( Token.TIMES ); /* cannot fail */
            } else if ( token.isMatch( Token.DIVIDE ) ) {
                operatorCode = BinaryOperator.DIV_OP;
                match( Token.DIVIDE ); /* cannot fail */
            } else {
                fatal( "Unreachable branch in parseTerm" );
            }
            ExpNode right = parseFactor( recoverSet.union( TERM_OPS_SET ) );
            term = new ExpNode.BinaryOpNode( pos, operatorCode, term, right );
        }
        endRule( "Term", recoverSet );
        return term;
    }
    /** Rule: Factor -> LPAREN Condition RPAREN | NUMBER | LValue  */
    private ExpNode parseFactor( TokenSet recoverSet ) {
        if( !beginRule( "Factor", FACTOR_START_SET, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode result = null;
        if( token.isMatch( Token.IDENTIFIER ) ) {
            result = parseLValue( recoverSet );
        } else if( token.isMatch( Token.NUMBER ) ) {
            result = new ExpNode.ConstNode( token.getPosn(), Type.INTEGER_TYPE,
                                         token.getIntValue() );
            match( Token.NUMBER ); /* cannot fail */
        } else if( token.isMatch( Token.LPAREN ) ) {
            match( Token.LPAREN ); /* cannot fail */
            result = parseCondition( recoverSet.union( Token.RPAREN ) );
            match( Token.RPAREN, recoverSet );
        } else {
            fatal( "Unreachable branch in Factor" );
        }
        endRule( "Factor", recoverSet );
        return result;
    }
    /** Rule: LValue -> IDENTIFIER */
    private ExpNode parseLValue( TokenSet recoverSet ) {
        if( !beginRule( "LValue", Token.IDENTIFIER, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode result = 
            new ExpNode.IdentifierNode( token.getPosn(), token.getName() );
        match( Token.IDENTIFIER ); /* cannot fail */
        endRule( "LValue", recoverSet );
        return result;
    }
    


/*********************** Private convenience Methods ************************/
    /** Assert that condition is true. Otherwise throw an error which should
     * abort the compiler immediately
     */
    private void pl0_assert( boolean condition, String m ) {
        if( !condition ) fatal( "Assertion failed! " + m );
    }
    /** Signal an error at the given position */
    private void error( String m, Position pos ) {
        errors.errorMessage( m, Severity.ERROR, pos );
    }
    /** Signal an error at the current token position */
    private void error( String m ) {
        error( m, token.getPosn() );
    }
    /** Signal a fatal error at the given position */
    private void fatal( String m, Position pos ) {
        errors.errorMessage( m, Severity.FATAL, pos );
    }
    /** Signal a fatal error at the current token position */
    private void fatal( String m ) {
        fatal( m, token.getPosn() );
    }
}
